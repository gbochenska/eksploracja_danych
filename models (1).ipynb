{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Wdt5IWrFgtY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "def train_model(dataset, model_type='svm', **kwargs):\n",
        "    \"\"\"\n",
        "    Funkcja trenująca model na podstawie podanego zbioru danych i modelu.\n",
        "\n",
        "    Args:\n",
        "        dataset: Ramka danych zawierająca cechy i etykiety.\n",
        "        model_type: Typ modelu do wytrenowania ('svm' dla SVM, 'logistic' dla regresji logistycznej, 'xgboost' dla XGBoost).\n",
        "        **kwargs: Dodatkowe argumenty przekazywane do konstruktora modelu.\n",
        "\n",
        "    Returns:\n",
        "        model: Wytrenowany model.\n",
        "        accuracy: Dokładność modelu na zestawie testowym.\n",
        "    \"\"\"\n",
        "    X = dataset.iloc[:, :-1]\n",
        "    y = dataset.iloc[:, -1]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if model_type == 'svm':\n",
        "        model = SVC(**kwargs)\n",
        "    elif model_type == 'logistic':\n",
        "        model = LogisticRegression(**kwargs)\n",
        "    elif model_type == 'xgboost':\n",
        "        model = xgb.XGBClassifier(**kwargs)\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end_train_time = time.time()\n",
        "    train_time = end_train_time - start_train_time\n",
        "    print(train_time)\n",
        "\n",
        "    start_predict_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    end_predict_time = time.time()\n",
        "    predict_time = end_predict_time - start_predict_time\n",
        "    print(predict_time)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return model, accuracy, precision, recall, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diabetes"
      ],
      "metadata": {
        "id": "c27bobQEMCRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zaimportuj dane diabetes\n",
        "diabetes = pd.read_csv(\"diabetes_data.csv\")\n",
        "\n",
        "# Wytrenuj modele SVM, regresji logistycznej i XGBoost za pomocą funkcji\n",
        "svm_model, svm_accuracy, svm_precision, svm_recall, svm_cm = train_model(diabetes, model_type='svm', kernel='rbf', C=1.0)\n",
        "logistic_model, logistic_accuracy, logistic_precision, logistic_recall, logistic_cm = train_model(diabetes, model_type='logistic')\n",
        "xgboost_model, xgboost_accuracy, xgboost_precision, xgboost_recall, xgboost_cm = train_model(diabetes, model_type='xgboost')\n",
        "\n",
        "print(\"Dokładność modelu SVM:\", svm_accuracy)\n",
        "print(\"Dokładność modelu regresji logistycznej: \", logistic_accuracy)\n",
        "print(\"Dokładność modelu XGBoost:\", xgboost_accuracy)\n",
        "\n",
        "print(\"Precyzja modelu SVM:\", svm_precision)\n",
        "print(\"Precyzja modelu regresji logistycznej: \", logistic_precision)\n",
        "print(\"Precyzja modelu XGBoost:\", xgboost_precision)\n",
        "\n",
        "print(\"Czułość modelu SVM:\", svm_recall)\n",
        "print(\"Czułość modelu regresji logistycznej: \", logistic_recall)\n",
        "print(\"Czułość modelu XGBoost:\", xgboost_recall)\n",
        "\n",
        "print(\"Macierz pomyłek modelu SVM: \", svm_cm)\n",
        "print(\"Macierz pomyłek regresji logistycznej: \", logistic_cm)\n",
        "print(\"Macierz pomyłek modelu XGBoost: \", xgboost_cm)\n"
      ],
      "metadata": {
        "id": "7QUagiqpLzdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cde5341-6506-423e-dd9c-c0e6407bbded"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129.84508776664734\n",
            "26.119346618652344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.539376974105835\n",
            "0.005644321441650391\n",
            "0.559699535369873\n",
            "0.027471303939819336\n",
            "Dokładność modelu SVM: 0.7482848857769291\n",
            "Dokładność modelu regresji logistycznej:  0.7440413041940731\n",
            "Dokładność modelu XGBoost: 0.7488506966546432\n",
            "Precyzja modelu SVM: 0.7212221095334685\n",
            "Precyzja modelu regresji logistycznej:  0.7307588805166846\n",
            "Precyzja modelu XGBoost: 0.7285079696890515\n",
            "Czułość modelu SVM: 0.8070648318910484\n",
            "Czułość modelu regresji logistycznej:  0.7704638955880266\n",
            "Czułość modelu XGBoost: 0.7910341892467017\n",
            "Macierz pomyłek modelu SVM:  [[4891 2199]\n",
            " [1360 5689]]\n",
            "Macierz pomyłek regresji logistycznej:  [[5089 2001]\n",
            " [1618 5431]]\n",
            "Macierz pomyłek modelu XGBoost:  [[5012 2078]\n",
            " [1473 5576]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypertension"
      ],
      "metadata": {
        "id": "yJyFMKNAME3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zaimportuj dane hypertension\n",
        "hypertension = pd.read_csv(\"hypertension_data.csv\")\n",
        "NaN_count = hypertension.isna().sum()\n",
        "hypertension = hypertension.dropna()\n",
        "\n",
        "# Wytrenuj modele SVM, regresji logistycznej i XGBoost za pomocą funkcji\n",
        "svm_model, svm_accuracy, svm_precision, svm_recall, svm_cm = train_model(hypertension, model_type='svm', kernel='rbf', C=1.0)\n",
        "logistic_model, logistic_accuracy, logistic_precision, logistic_recall, logistic_cm = train_model(hypertension, model_type='logistic')\n",
        "xgboost_model, xgboost_accuracy, xgboost_precision, xgboost_recall, xgboost_cm = train_model(hypertension, model_type='xgboost')\n",
        "\n",
        "print(\"Dokładność modelu SVM:\", svm_accuracy)\n",
        "print(\"Dokładność modelu regresji logistycznej:\", logistic_accuracy)\n",
        "print(\"Dokładność modelu XGBoost:\", xgboost_accuracy)\n",
        "\n",
        "print(\"Precyzja modelu SVM:\", svm_precision)\n",
        "print(\"Precyzja modelu regresji logistycznej:\", logistic_precision)\n",
        "print(\"Precyzja modelu XGBoost:\", xgboost_precision)\n",
        "\n",
        "print(\"Czułość modelu SVM:\", svm_recall)\n",
        "print(\"Czułość modelu regresji logistycznej:\", logistic_recall)\n",
        "print(\"Czułość modelu XGBoost:\", xgboost_recall)\n",
        "\n",
        "print(\"Macierz pomyłek modelu SVM: \", svm_cm)\n",
        "print(\"Macierz pomyłek regresji logistycznej: \", logistic_cm)\n",
        "print(\"Macierz pomyłek modelu XGBoost: \", xgboost_cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5nc7eKGMH1h",
        "outputId": "0a0e09ad-1977-4d7f-c61a-a10b687fe3e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.52316379547119\n",
            "5.047417879104614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21774744987487793\n",
            "0.003140687942504883\n",
            "0.29167842864990234\n",
            "0.013245582580566406\n",
            "Dokładność modelu SVM: 0.7536454336147352\n",
            "Dokładność modelu regresji logistycznej: 0.8451650038372985\n",
            "Dokładność modelu XGBoost: 1.0\n",
            "Precyzja modelu SVM: 0.7468548634550476\n",
            "Precyzja modelu regresji logistycznej: 0.8288146279949559\n",
            "Precyzja modelu XGBoost: 1.0\n",
            "Czułość modelu SVM: 0.841341168337366\n",
            "Czułość modelu regresji logistycznej: 0.908745247148289\n",
            "Czułość modelu XGBoost: 1.0\n",
            "Macierz pomyłek modelu SVM:  [[1494  825]\n",
            " [ 459 2434]]\n",
            "Macierz pomyłek regresji logistycznej:  [[1776  543]\n",
            " [ 264 2629]]\n",
            "Macierz pomyłek modelu XGBoost:  [[2319    0]\n",
            " [   0 2893]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stroke"
      ],
      "metadata": {
        "id": "nazuPt7dMIDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stroke = pd.read_csv(\"stroke_data.csv\")\n",
        "NaN_count = stroke.isna().sum()\n",
        "stroke = stroke.dropna()\n",
        "\n",
        "svm_model, svm_accuracy, svm_precision, svm_recall, svm_cm = train_model(stroke, model_type='svm', kernel='rbf', C=1.0)\n",
        "logistic_model, logistic_accuracy, logistic_precision, logistic_recall, logistic_cm = train_model(stroke, model_type='logistic')\n",
        "xgboost_model, xgboost_accuracy, xgboost_precision, xgboost_recall, xgboost_cm = train_model(stroke, model_type='xgboost')\n",
        "\n",
        "\n",
        "print(\"Dokładność modelu SVM:\", svm_accuracy)\n",
        "print(\"Dokładność modelu regresji logistycznej:\", logistic_accuracy)\n",
        "print(\"Dokładność modelu XGBoost:\", xgboost_accuracy)\n",
        "\n",
        "print(\"Precyzja modelu SVM:\", svm_precision)\n",
        "print(\"Precyzja modelu regresji logistycznej:\", logistic_precision)\n",
        "print(\"Precyzja modelu XGBoost:\", xgboost_precision)\n",
        "\n",
        "print(\"Czułość modelu SVM:\", svm_recall)\n",
        "print(\"Czułość modelu regresji logistycznej:\", logistic_recall)\n",
        "print(\"Czułość modelu XGBoost:\", xgboost_recall)\n",
        "\n",
        "print(\"Macierz pomyłek modelu SVM: \", svm_cm)\n",
        "print(\"Macierz pomyłek regresji logistycznej: \", logistic_cm)\n",
        "print(\"Macierz pomyłek modelu XGBoost: \", xgboost_cm)"
      ],
      "metadata": {
        "id": "cxmN41EKMTOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e32f21-14f1-4aca-c1d9-0389224817fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.70302224159241\n",
            "10.791438102722168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5876646041870117\n",
            "0.0033016204833984375\n",
            "0.7456278800964355\n",
            "0.016674041748046875\n",
            "Dokładność modelu SVM: 0.651185529210462\n",
            "Dokładność modelu regresji logistycznej: 0.6786849181129309\n",
            "Dokładność modelu XGBoost: 0.9973111708628697\n",
            "Precyzja modelu SVM: 0.7076502732240437\n",
            "Precyzja modelu regresji logistycznej: 0.7033587355348575\n",
            "Precyzja modelu XGBoost: 0.9946236559139785\n",
            "Czułość modelu SVM: 0.509090909090909\n",
            "Czułość modelu regresji logistycznej: 0.6122850122850123\n",
            "Czułość modelu XGBoost: 1.0\n",
            "Macierz pomyłek modelu SVM:  [[3256  856]\n",
            " [1998 2072]]\n",
            "Macierz pomyłek regresji logistycznej:  [[3061 1051]\n",
            " [1578 2492]]\n",
            "Macierz pomyłek modelu XGBoost:  [[4090   22]\n",
            " [   0 4070]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strojenie hiperparaemtrów - GridSearchCV"
      ],
      "metadata": {
        "id": "pidS8Ss14-PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_svm_model(data):\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "    svm = SVC()\n",
        "    grid_search = GridSearchCV(svm, param_grid, cv=3, scoring='recall')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_svm_model = grid_search.best_estimator_\n",
        "    recall = grid_search.best_score_\n",
        "    return best_svm_model, recall\n",
        "\n",
        "def tune_logistic_regression(data):\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'solver': ['liblinear', 'lbfgs']\n",
        "    }\n",
        "    logistic = LogisticRegression(max_iter=1000)\n",
        "    grid_search = GridSearchCV(logistic, param_grid, cv=3, scoring='recall')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_logistic_model = grid_search.best_estimator_\n",
        "    recall = grid_search.best_score_\n",
        "    return best_logistic_model, recall\n",
        "\n",
        "def tune_xgboost_model(data):\n",
        "    X = data.iloc[:, :-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.1, 0.3],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7, 0.9],\n",
        "        'colsample_bytree': [0.5, 0.7, 0.9]\n",
        "    }\n",
        "    xgboost = xgb.XGBClassifier()\n",
        "    grid_search = GridSearchCV(xgboost, param_grid, cv=3, scoring='recall')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_xgboost_model = grid_search.best_estimator_\n",
        "    recall = grid_search.best_score_\n",
        "    return best_xgboost_model, recall"
      ],
      "metadata": {
        "id": "aBjV9K_y5CEx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes = pd.read_csv(\"diabetes_data.csv\")\n",
        "# Zaimportuj dane hypertension\n",
        "hypertension = pd.read_csv(\"hypertension_data.csv\")\n",
        "NaN_count = hypertension.isna().sum()\n",
        "hypertension = hypertension.dropna()\n",
        "stroke = pd.read_csv(\"stroke_data.csv\")\n",
        "NaN_count = stroke.isna().sum()\n",
        "stroke = stroke.dropna()\n",
        "# best_svm_diabetes, accuracy_svm_diabetes = tune_svm_model(diabetes)\n",
        "# best_logistic_diabetes, accuracy_logistic_diabetes = tune_logistic_regression(diabetes)\n",
        "# print(best_logistic_diabetes, accuracy_logistic_diabetes)\n",
        "# best_xgboost_diabetes, accuracy_xgboost_diabetes = tune_xgboost_model(diabetes)\n",
        "# print(best_xgboost_diabetes, accuracy_xgboost_diabetes)\n",
        "\n",
        "# best_svm_hypertension, accuracy_svm_hypertension = tune_svm_model(hypertension)\n",
        "best_logistic_hypertension, accuracy_logistic_hypertension = tune_logistic_regression(hypertension)\n",
        "print(best_logistic_hypertension, accuracy_logistic_hypertension)\n",
        "best_xgboost_hypertension, accuracy_xgboost_hypertension = tune_xgboost_model(hypertension)\n",
        "print(best_xgboost_hypertension, accuracy_xgboost_hypertension)\n",
        "\n",
        "# best_svm_stroke, accuracy_svm_stroke = tune_svm_model(stroke)\n",
        "# best_logistic_stroke, accuracy_logistic_stroke = tune_logistic_regression(stroke)\n",
        "# print(best_logistic_stroke, accuracy_logistic_stroke)\n",
        "# best_xgboost_stroke, accuracy_xgboost_stroke = tune_xgboost_model(stroke)\n",
        "# print(best_xgboost_stroke, accuracy_xgboost_stroke)"
      ],
      "metadata": {
        "id": "oa0c5JAh5-Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff93a43-fc0c-4513-b952-05bcb2c9abb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, max_iter=1000, solver='liblinear') 0.7682085710147014\n",
            "LogisticRegression(C=1, max_iter=1000, solver='liblinear') 0.9257533703731449\n"
          ]
        }
      ]
    }
  ]
}